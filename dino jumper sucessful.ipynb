{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 #opencv\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#keras imports\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"chrome://dino\"\n",
    "chrome_driver_path = \"c:/abc/chromedriver.exe\"\n",
    "loss_file_path = \"./objects/loss_df.csv\"\n",
    "actions_file_path = \"./objects/actions_df.csv\"\n",
    "q_value_file_path = \"./objects/q_values.csv\"\n",
    "scores_file_path = \"./objects/scores_df.csv\"\n",
    "\n",
    "#scripts\n",
    "#create id for canvas for faster selection from DOM\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "\n",
    "#get image from canvas\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); \\\n",
    "return canvasRunner.toDataURL().substring(22)\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Game class: Selenium interfacing between the python and browser\n",
    "* __init__():  Launch the broswer window using the attributes in chrome_options\n",
    "* get_crashed() : return true if the agent as crashed on an obstacles. Gets javascript variable from game decribing the state\n",
    "* get_playing(): true if game in progress, false is crashed or paused\n",
    "* restart() : sends a signal to browser-javascript to restart the game\n",
    "* press_up(): sends a single to press up get to the browser\n",
    "* get_score(): gets current game score from javascript variables.\n",
    "* pause(): pause the game\n",
    "* resume(): resume a paused game if not crashed\n",
    "* end(): close the browser and end the game\n",
    "'''\n",
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self._driver = webdriver.Chrome(executable_path = chrome_driver_path,chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.get('chrome://dino')\n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "    def get_crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array) # the javascript object is of type array with score in the formate[1,0,0] which is 100.\n",
    "        return int(score)\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoAgent:\n",
    "    def __init__(self,game): #takes game as input for taking actions\n",
    "        self._game = game; \n",
    "        self.jump(); #to start the game, we need to jump once\n",
    "    def is_running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.get_crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_sate:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img() #display the processed image on screen using openCV, implemented using python coroutine \n",
    "        self._display.__next__() # initiliaze the display coroutine \n",
    "    def get_state(self,actions):\n",
    "        actions_df.loc[len(actions_df)] = actions[1] # storing actions in a dataframe\n",
    "        score = self._game.get_score() \n",
    "        reward = 0.1\n",
    "        is_over = False #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "        image = grab_screen(self._game._driver) \n",
    "        self._display.send(image) #display the image on screen\n",
    "        if self._agent.is_crashed():\n",
    "            scores_df.loc[len(loss_df)] = score # log the score when game is over\n",
    "            self._game.restart()\n",
    "            reward = -1\n",
    "            is_over = True\n",
    "        return image, reward, is_over #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('objects/'+ name + '.pkl', 'wb') as f: #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_obj(name ):\n",
    "    if not os.path.exists(\"./objects\"):\n",
    "        os.mkdir(\"./objects\")\n",
    "    with open('objects/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = process_img(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def process_img(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #RGB to Grey Scale\n",
    "    image = image[:300, :500] #Crop Region of Interest(ROI)\n",
    "    image = cv2.resize(image, (80,80))\n",
    "    return  image\n",
    "\n",
    "def show_img(graphs = False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)        \n",
    "        imS = cv2.resize(screen, (800, 400)) \n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns =['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns = ['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns = ['actions'])\n",
    "q_values_df =pd.read_csv(actions_file_path) if os.path.isfile(q_value_file_path) else pd.DataFrame(columns = ['qvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 2 # possible actions: jump, do nothing\n",
    "GAMMA = 0.99 # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100. # timesteps to observe before training\n",
    "EXPLORE = 100000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH = 16 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 80,80\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables saved as checkpoints to filesystem to resume training from the same step# train \n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_obj(INITIAL_EPSILON,\"epsilon\")\n",
    "    t = 0\n",
    "    save_obj(t,\"time\")\n",
    "    D = deque()\n",
    "    save_obj(D,\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Call only once to init file structure\n",
    "'''\n",
    "init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), padding='same',strides=(4, 4),input_shape=(img_cols,img_rows,img_channels)))  #80*80*4\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4),strides=(2, 2),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3),strides=(1, 1),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    \n",
    "    #create model file if not present\n",
    "    if not os.path.isfile(loss_file_path):\n",
    "        model.save_weights('model.h5')\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate wherther the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "def trainNetwork(model,game_state,observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = load_obj(\"D\") #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] =1 #0 => do nothing,\n",
    "                     #1=> jump\n",
    "    \n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing) # get next step after performing the action\n",
    "    \n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) # stack 4 images to create placeholder input\n",
    "    \n",
    "\n",
    "    \n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "    \n",
    "    initial_state = s_t \n",
    "\n",
    "    if observe :\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = load_obj(\"epsilon\") \n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "\n",
    "    t = load_obj(\"time\") # resume from the previous time step stored in file system\n",
    "    while (True): #endless running\n",
    "        \n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0 #reward at 4\n",
    "        a_t = np.zeros([ACTIONS]) # action at t\n",
    "        \n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0: #parameter to skip frames for actions\n",
    "            if  random.random() <= epsilon: #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else: # predict the output\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)         # chosing index with maximum q value\n",
    "                action_index = max_Q \n",
    "                a_t[action_index] = 1        # o=> do nothing, 1=> jump\n",
    "                \n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE \n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('fps: {0}'.format(1 / (time.time()-last_time))) # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) # append the new image to input stack and remove the first one\n",
    "        \n",
    "        \n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE: \n",
    "            \n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "            inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]    # 4D stack of images\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]   #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]   #next state\n",
    "                terminal = minibatch[i][4]   #wheather the agent died or survided due the action\n",
    "                \n",
    "\n",
    "                inputs[i:i + 1] = state_t    \n",
    "\n",
    "                targets[i] = model.predict(state_t)  # predicted q values\n",
    "                Q_sa = model.predict(state_t1)      #predict q values for next step\n",
    "                \n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t # if terminated, only equals reward\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "            q_values_df.loc[len(q_values_df)] = np.max(Q_sa)\n",
    "        s_t = initial_state if terminal else s_t1 #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "        \n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            game_state._game.pause() #pause game while saving to filesystem\n",
    "            model.save_weights(\"model.h5\", overwrite=True)\n",
    "            save_obj(D,\"D\") #saving episodes\n",
    "            save_obj(t,\"time\") #caching time steps\n",
    "            save_obj(epsilon,\"epsilon\") #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects/loss_df.csv\",index=False)\n",
    "            scores_df.to_csv(\"./objects/scores_df.csv\",index=False)\n",
    "            actions_df.to_csv(\"./objects/actions_df.csv\",index=False)\n",
    "            q_values_df.to_csv(q_value_file_path,index=False)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "            clear_output()\n",
    "            game_state._game.resume()\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state,             \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t,             \"/ Q_MAX \" , np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def playGame(observe=False):\n",
    "    game = Game()\n",
    "    dino = DinoAgent(game)\n",
    "    game_state = Game_sate(dino,game)    \n",
    "    model = buildmodel()\n",
    "    try:\n",
    "        trainNetwork(model,game_state,observe=observe)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we build the model\n",
      "We finish building the model\n",
      "fps: 1.4103563901259344\n",
      "TIMESTEP 1 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.819757010774051\n",
      "TIMESTEP 2 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 3 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.986305611200729\n",
      "TIMESTEP 4 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.986225195909357\n",
      "TIMESTEP 5 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872184064634538\n",
      "TIMESTEP 6 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 16.392452358247223\n",
      "TIMESTEP 7 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27533173720732\n",
      "TIMESTEP 8 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 20.832256366192006\n",
      "TIMESTEP 9 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.819757010774051\n",
      "TIMESTEP 10 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.819796194074101\n",
      "TIMESTEP 11 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.38369900897134\n",
      "TIMESTEP 12 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.392516424548692\n",
      "TIMESTEP 13 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.392452358247223\n",
      "TIMESTEP 14 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.39258049135094\n",
      "TIMESTEP 15 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.65746446570299\n",
      "TIMESTEP 16 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872124000968757\n",
      "TIMESTEP 17 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27543965547851\n",
      "TIMESTEP 18 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.392452358247223\n",
      "TIMESTEP 19 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 10.637719827739256\n",
      "TIMESTEP 20 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872063937757561\n",
      "TIMESTEP 21 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 16.128092531780883\n",
      "TIMESTEP 22 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.128154548355962\n",
      "TIMESTEP 23 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 9.090385782401388\n",
      "TIMESTEP 24 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.392516424548692\n",
      "TIMESTEP 25 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.624095272507832\n",
      "TIMESTEP 26 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 1.602472075299267\n",
      "TIMESTEP 27 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.128154548355962\n",
      "TIMESTEP 28 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 1.779257415368378\n",
      "TIMESTEP 29 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.392516424548692\n",
      "TIMESTEP 30 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.657502663194203\n",
      "TIMESTEP 31 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 7.999542262520074\n",
      "TIMESTEP 32 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 33 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872124000968757\n",
      "TIMESTEP 34 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 35 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.392516424548692\n",
      "TIMESTEP 36 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27543965547851\n",
      "TIMESTEP 37 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27533173720732\n",
      "TIMESTEP 38 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.128092531780883\n",
      "TIMESTEP 39 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27543965547851\n",
      "TIMESTEP 40 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.128030515682738\n",
      "TIMESTEP 41 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27543965547851\n",
      "TIMESTEP 42 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27533173720732\n",
      "TIMESTEP 43 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.73800194871157\n",
      "TIMESTEP 44 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 45 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.819796194074101\n",
      "TIMESTEP 46 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.73800194871157\n",
      "TIMESTEP 47 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.38369900897134\n",
      "TIMESTEP 48 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 22.221007236932728\n",
      "TIMESTEP 49 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 50 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 16.128154548355962\n",
      "TIMESTEP 51 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872124000968757\n",
      "TIMESTEP 52 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 21.73777662606893\n",
      "TIMESTEP 53 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.819835377613678\n",
      "TIMESTEP 54 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 16.128092531780883\n",
      "TIMESTEP 55 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.624095272507832\n",
      "TIMESTEP 56 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.986265403430552\n",
      "TIMESTEP 57 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.73777662606893\n",
      "TIMESTEP 58 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 59 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.624153473644999\n",
      "TIMESTEP 60 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.986265403430552\n",
      "TIMESTEP 61 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 1.7792566605934244\n",
      "TIMESTEP 62 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 1.779258170143972\n",
      "TIMESTEP 63 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.39258049135094\n",
      "TIMESTEP 64 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 1.6862445544761442\n",
      "TIMESTEP 65 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 14.491951227096672\n",
      "TIMESTEP 66 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -1 / Q_MAX  0 / Loss  0\n",
      "fps: 7.518358055119874\n",
      "TIMESTEP 67 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.73800194871157\n",
      "TIMESTEP 68 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.128092531780883\n",
      "TIMESTEP 69 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 20.83204942907236\n",
      "TIMESTEP 70 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 71 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.73800194871157\n",
      "TIMESTEP 72 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872063937757561\n",
      "TIMESTEP 73 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872124000968757\n",
      "TIMESTEP 74 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27543965547851\n",
      "TIMESTEP 75 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 21.73777662606893\n",
      "TIMESTEP 76 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 77 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 78 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27543965547851\n",
      "TIMESTEP 79 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 20.83204942907236\n",
      "TIMESTEP 80 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 81 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.128154548355962\n",
      "TIMESTEP 82 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27533173720732\n",
      "TIMESTEP 83 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 20.832152897118277\n",
      "TIMESTEP 84 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 20.832152897118277\n",
      "TIMESTEP 85 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 16.66568920782126\n",
      "TIMESTEP 86 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 87 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872184064634538\n",
      "TIMESTEP 88 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.872063937757561\n",
      "TIMESTEP 89 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.392516424548692\n",
      "TIMESTEP 90 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 15.872063937757561\n",
      "TIMESTEP 91 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 92 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.624153473644999\n",
      "TIMESTEP 93 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 22.220889512860587\n",
      "TIMESTEP 94 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.65754086091596\n",
      "TIMESTEP 95 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.737889286806357\n",
      "TIMESTEP 96 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 15.15064297066898\n",
      "TIMESTEP 97 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.948189334001405\n",
      "TIMESTEP 98 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 20.83204942907236\n",
      "TIMESTEP 99 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 21.27533173720732\n",
      "TIMESTEP 100 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 16.128154548355962\n",
      "TIMESTEP 101 / STATE explore / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "fps: 12.819757010774051\n",
      "TIMESTEP 102 / STATE explore / EPSILON 0.099999001 / ACTION 1 / REWARD 0.1 / Q_MAX  1.54867 / Loss  0.226353913546\n",
      "fps: 0.43325079715364323\n",
      "TIMESTEP 103 / STATE explore / EPSILON 0.099998002 / ACTION 1 / REWARD 0.1 / Q_MAX  1.95765 / Loss  0.0763018801808\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 104 / STATE explore / EPSILON 0.099997003 / ACTION 1 / REWARD 0.1 / Q_MAX  2.29694 / Loss  0.0441025197506\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 105 / STATE explore / EPSILON 0.099996004 / ACTION 1 / REWARD 0.1 / Q_MAX  2.12406 / Loss  0.196686267853\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 106 / STATE explore / EPSILON 0.099995005 / ACTION 0 / REWARD 0.1 / Q_MAX  2.08569 / Loss  0.0490277968347\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 107 / STATE explore / EPSILON 0.099994006 / ACTION 0 / REWARD 0.1 / Q_MAX  0.82469 / Loss  0.0456147827208\n",
      "----------Random Action----------\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 108 / STATE explore / EPSILON 0.099993007 / ACTION 1 / REWARD 0.1 / Q_MAX  2.16351 / Loss  0.0267549771816\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 109 / STATE explore / EPSILON 0.099992008 / ACTION 0 / REWARD 0.1 / Q_MAX  2.1278 / Loss  0.261124283075\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 110 / STATE explore / EPSILON 0.09999100899999999 / ACTION 1 / REWARD 0.1 / Q_MAX  2.45296 / Loss  0.0450314581394\n",
      "fps: 7.142438231923397\n",
      "TIMESTEP 111 / STATE explore / EPSILON 0.09999000999999999 / ACTION 0 / REWARD 0.1 / Q_MAX  2.01036 / Loss  0.00655133789405\n",
      "fps: 5.181146637810488\n",
      "TIMESTEP 112 / STATE explore / EPSILON 0.09998901099999999 / ACTION 0 / REWARD -1 / Q_MAX  2.81245 / Loss  0.293565094471\n",
      "fps: 5.524578244697105\n",
      "TIMESTEP 113 / STATE explore / EPSILON 0.09998801199999999 / ACTION 1 / REWARD 0.1 / Q_MAX  2.32402 / Loss  0.215851217508\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 114 / STATE explore / EPSILON 0.09998701299999999 / ACTION 1 / REWARD 0.1 / Q_MAX  2.44277 / Loss  0.0260541364551\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 115 / STATE explore / EPSILON 0.09998601399999998 / ACTION 0 / REWARD 0.1 / Q_MAX  2.40613 / Loss  0.123796083033\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 116 / STATE explore / EPSILON 0.09998501499999998 / ACTION 0 / REWARD 0.1 / Q_MAX  2.24812 / Loss  0.135519951582\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 117 / STATE explore / EPSILON 0.09998401599999998 / ACTION 0 / REWARD 0.1 / Q_MAX  2.52089 / Loss  0.0439485162497\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 118 / STATE explore / EPSILON 0.09998301699999998 / ACTION 0 / REWARD 0.1 / Q_MAX  2.48434 / Loss  0.0348093993962\n",
      "fps: 7.142450394730568\n",
      "TIMESTEP 119 / STATE explore / EPSILON 0.09998201799999998 / ACTION 0 / REWARD 0.1 / Q_MAX  2.38219 / Loss  0.113892816007\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 120 / STATE explore / EPSILON 0.09998101899999998 / ACTION 0 / REWARD 0.1 / Q_MAX  1.53359 / Loss  0.0348686538637\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 121 / STATE explore / EPSILON 0.09998001999999998 / ACTION 0 / REWARD 0.1 / Q_MAX  2.4543 / Loss  0.0551565252244\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 122 / STATE explore / EPSILON 0.09997902099999997 / ACTION 0 / REWARD 0.1 / Q_MAX  2.57065 / Loss  0.145857587457\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 123 / STATE explore / EPSILON 0.09997802199999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.31048 / Loss  0.0286356396973\n",
      "fps: 1.392678244250223\n",
      "TIMESTEP 124 / STATE explore / EPSILON 0.09997702299999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.31001 / Loss  0.0520255938172\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 125 / STATE explore / EPSILON 0.09997602399999997 / ACTION 1 / REWARD 0.1 / Q_MAX  2.60289 / Loss  0.164912372828\n",
      "fps: 7.04185351521511\n",
      "TIMESTEP 126 / STATE explore / EPSILON 0.09997502499999997 / ACTION 0 / REWARD 0.1 / Q_MAX  2.22039 / Loss  0.0452195443213\n",
      "fps: 6.493132701715276\n",
      "TIMESTEP 127 / STATE explore / EPSILON 0.09997402599999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.9651 / Loss  0.0443271137774\n",
      "----------Random Action----------\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 128 / STATE explore / EPSILON 0.09997302699999996 / ACTION 1 / REWARD 0.1 / Q_MAX  2.66959 / Loss  0.0852917134762\n",
      "fps: 7.091789236614246\n",
      "TIMESTEP 129 / STATE explore / EPSILON 0.09997202799999996 / ACTION 0 / REWARD 0.1 / Q_MAX  0.739874 / Loss  0.0315397158265\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 130 / STATE explore / EPSILON 0.09997102899999996 / ACTION 0 / REWARD 0.1 / Q_MAX  2.72989 / Loss  0.0197455678135\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 131 / STATE explore / EPSILON 0.09997002999999996 / ACTION 0 / REWARD 0.1 / Q_MAX  2.84292 / Loss  0.0484128221869\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 132 / STATE explore / EPSILON 0.09996903099999996 / ACTION 0 / REWARD 0.1 / Q_MAX  2.69627 / Loss  0.101239986718\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 133 / STATE explore / EPSILON 0.09996803199999996 / ACTION 0 / REWARD 0.1 / Q_MAX  2.17107 / Loss  0.0269274897873\n",
      "fps: 7.1938282319284035\n",
      "TIMESTEP 134 / STATE explore / EPSILON 0.09996703299999996 / ACTION 0 / REWARD 0.1 / Q_MAX  2.88682 / Loss  0.0734348446131\n",
      "fps: 0.8554015282718879\n",
      "TIMESTEP 135 / STATE explore / EPSILON 0.09996603399999995 / ACTION 0 / REWARD -1 / Q_MAX  3.0141 / Loss  0.0996125936508\n",
      "fps: 0.37007520876102346\n",
      "TIMESTEP 136 / STATE explore / EPSILON 0.09996503499999995 / ACTION 0 / REWARD 0.1 / Q_MAX  2.64604 / Loss  0.245264917612\n",
      "----------Random Action----------\n",
      "fps: 3.787660742667245\n",
      "TIMESTEP 137 / STATE explore / EPSILON 0.09996403599999995 / ACTION 0 / REWARD 0.1 / Q_MAX  3.33728 / Loss  0.0492201149464\n",
      "fps: 6.493132701715276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 138 / STATE explore / EPSILON 0.09996303699999995 / ACTION 0 / REWARD 0.1 / Q_MAX  2.71934 / Loss  0.122187934816\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 139 / STATE explore / EPSILON 0.09996203799999995 / ACTION 0 / REWARD 0.1 / Q_MAX  2.37618 / Loss  0.143545269966\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 140 / STATE explore / EPSILON 0.09996103899999995 / ACTION 0 / REWARD 0.1 / Q_MAX  3.78933 / Loss  0.0426059663296\n",
      "fps: 5.916820665897376\n",
      "TIMESTEP 141 / STATE explore / EPSILON 0.09996003999999994 / ACTION 1 / REWARD 0.1 / Q_MAX  2.61015 / Loss  0.111210919917\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 142 / STATE explore / EPSILON 0.09995904099999994 / ACTION 0 / REWARD 0.1 / Q_MAX  2.40603 / Loss  0.0343694128096\n",
      "fps: 6.328751331597101\n",
      "TIMESTEP 143 / STATE explore / EPSILON 0.09995804199999994 / ACTION 0 / REWARD 0.1 / Q_MAX  2.95319 / Loss  0.0623238161206\n",
      "fps: 6.493132701715276\n",
      "TIMESTEP 144 / STATE explore / EPSILON 0.09995704299999994 / ACTION 0 / REWARD 0.1 / Q_MAX  3.06366 / Loss  0.217566251755\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 145 / STATE explore / EPSILON 0.09995604399999994 / ACTION 1 / REWARD 0.1 / Q_MAX  2.51679 / Loss  0.0700040310621\n",
      "fps: 5.318846424051515\n",
      "TIMESTEP 146 / STATE explore / EPSILON 0.09995504499999994 / ACTION 1 / REWARD 0.1 / Q_MAX  2.84044 / Loss  0.217304512858\n",
      "fps: 5.88201208010961\n",
      "TIMESTEP 147 / STATE explore / EPSILON 0.09995404599999994 / ACTION 1 / REWARD 0.1 / Q_MAX  2.85392 / Loss  0.0373084135354\n",
      "fps: 5.127962363435413\n",
      "TIMESTEP 148 / STATE explore / EPSILON 0.09995304699999993 / ACTION 1 / REWARD -1 / Q_MAX  2.99887 / Loss  0.0409013442695\n",
      "----------Random Action----------\n",
      "fps: 1.4705061133420703\n",
      "TIMESTEP 149 / STATE explore / EPSILON 0.09995204799999993 / ACTION 0 / REWARD 0.1 / Q_MAX  3.03951 / Loss  0.0465542003512\n",
      "fps: 1.1247949154587753\n",
      "TIMESTEP 150 / STATE explore / EPSILON 0.09995104899999993 / ACTION 0 / REWARD 0.1 / Q_MAX  3.08435 / Loss  0.0638110265136\n",
      "----------Random Action----------\n",
      "fps: 5.88201208010961\n",
      "TIMESTEP 151 / STATE explore / EPSILON 0.09995004999999993 / ACTION 1 / REWARD 0.1 / Q_MAX  3.08797 / Loss  0.0571138076484\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 152 / STATE explore / EPSILON 0.09994905099999993 / ACTION 0 / REWARD 0.1 / Q_MAX  2.9181 / Loss  0.0275546759367\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 153 / STATE explore / EPSILON 0.09994805199999993 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.0882499 / Loss  0.0999575555325\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 154 / STATE explore / EPSILON 0.09994705299999992 / ACTION 0 / REWARD 0.1 / Q_MAX  3.22624 / Loss  0.151042297482\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 155 / STATE explore / EPSILON 0.09994605399999992 / ACTION 0 / REWARD 0.1 / Q_MAX  3.22757 / Loss  0.0852607041597\n",
      "fps: 6.369056585436964\n",
      "TIMESTEP 156 / STATE explore / EPSILON 0.09994505499999992 / ACTION 0 / REWARD 0.1 / Q_MAX  3.2004 / Loss  0.0269513186067\n",
      "fps: 5.916820665897376\n",
      "TIMESTEP 157 / STATE explore / EPSILON 0.09994405599999992 / ACTION 0 / REWARD 0.1 / Q_MAX  2.47945 / Loss  0.0119157833979\n",
      "fps: 5.318846424051515\n",
      "TIMESTEP 158 / STATE explore / EPSILON 0.09994305699999992 / ACTION 1 / REWARD 0.1 / Q_MAX  2.08356 / Loss  0.0454056821764\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 159 / STATE explore / EPSILON 0.09994205799999992 / ACTION 1 / REWARD 0.1 / Q_MAX  3.22904 / Loss  0.0435948595405\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 160 / STATE explore / EPSILON 0.09994105899999992 / ACTION 0 / REWARD 0.1 / Q_MAX  3.20541 / Loss  0.0331312306225\n",
      "fps: 7.142450394730568\n",
      "TIMESTEP 161 / STATE explore / EPSILON 0.09994005999999991 / ACTION 0 / REWARD 0.1 / Q_MAX  3.34096 / Loss  0.103195652366\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 162 / STATE explore / EPSILON 0.09993906099999991 / ACTION 0 / REWARD 0.1 / Q_MAX  3.44255 / Loss  0.0399738103151\n",
      "fps: 4.565944485448604\n",
      "TIMESTEP 163 / STATE explore / EPSILON 0.09993806199999991 / ACTION 0 / REWARD 0.1 / Q_MAX  3.41863 / Loss  0.0146815311164\n",
      "fps: 7.193840570388703\n",
      "TIMESTEP 164 / STATE explore / EPSILON 0.09993706299999991 / ACTION 0 / REWARD 0.1 / Q_MAX  3.48192 / Loss  0.0538102015853\n",
      "fps: 7.04185351521511\n",
      "TIMESTEP 165 / STATE explore / EPSILON 0.09993606399999991 / ACTION 0 / REWARD 0.1 / Q_MAX  2.36268 / Loss  0.0435799174011\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 166 / STATE explore / EPSILON 0.0999350649999999 / ACTION 0 / REWARD 0.1 / Q_MAX  3.50814 / Loss  0.044420003891\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 167 / STATE explore / EPSILON 0.0999340659999999 / ACTION 1 / REWARD 0.1 / Q_MAX  3.58297 / Loss  0.0932980030775\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 168 / STATE explore / EPSILON 0.0999330669999999 / ACTION 1 / REWARD 0.1 / Q_MAX  3.44914 / Loss  0.101073846221\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 169 / STATE explore / EPSILON 0.0999320679999999 / ACTION 0 / REWARD 0.1 / Q_MAX  3.84242 / Loss  0.0269388854504\n",
      "fps: 7.142450394730568\n",
      "TIMESTEP 170 / STATE explore / EPSILON 0.0999310689999999 / ACTION 0 / REWARD 0.1 / Q_MAX  2.18426 / Loss  0.0367415510118\n",
      "fps: 7.142450394730568\n",
      "TIMESTEP 171 / STATE explore / EPSILON 0.0999300699999999 / ACTION 0 / REWARD 0.1 / Q_MAX  3.27663 / Loss  0.0513855330646\n",
      "----------Random Action----------\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 172 / STATE explore / EPSILON 0.0999290709999999 / ACTION 0 / REWARD 0.1 / Q_MAX  3.4939 / Loss  0.209720298648\n",
      "fps: 7.091789236614246\n",
      "TIMESTEP 173 / STATE explore / EPSILON 0.0999280719999999 / ACTION 0 / REWARD 0.1 / Q_MAX  2.19289 / Loss  0.045711543411\n",
      "----------Random Action----------\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 174 / STATE explore / EPSILON 0.0999270729999999 / ACTION 0 / REWARD 0.1 / Q_MAX  3.73721 / Loss  0.146276190877\n",
      "----------Random Action----------\n",
      "fps: 6.210830108940785\n",
      "TIMESTEP 175 / STATE explore / EPSILON 0.09992607399999989 / ACTION 0 / REWARD -1 / Q_MAX  3.33262 / Loss  0.105182647705\n",
      "fps: 0.8474089530732309\n",
      "TIMESTEP 176 / STATE explore / EPSILON 0.09992507499999989 / ACTION 1 / REWARD 0.1 / Q_MAX  3.50538 / Loss  0.492941588163\n",
      "fps: 0.2747857772961768\n",
      "TIMESTEP 177 / STATE explore / EPSILON 0.09992407599999989 / ACTION 1 / REWARD -1 / Q_MAX  3.6223 / Loss  0.134597346187\n",
      "fps: 0.6565617131105276\n",
      "TIMESTEP 178 / STATE explore / EPSILON 0.09992307699999989 / ACTION 0 / REWARD 0.1 / Q_MAX  3.81283 / Loss  0.408396661282\n",
      "fps: 0.8424117339409077\n",
      "TIMESTEP 179 / STATE explore / EPSILON 0.09992207799999989 / ACTION 1 / REWARD 0.1 / Q_MAX  3.18458 / Loss  0.0476881489158\n",
      "----------Random Action----------\n",
      "fps: 1.3946203609124956\n",
      "TIMESTEP 180 / STATE explore / EPSILON 0.09992107899999988 / ACTION 1 / REWARD 0.1 / Q_MAX  4.05479 / Loss  0.186053439975\n",
      "fps: 0.7733537185956147\n",
      "TIMESTEP 181 / STATE explore / EPSILON 0.09992007999999988 / ACTION 1 / REWARD -1 / Q_MAX  2.35872 / Loss  0.909152507782\n",
      "fps: 0.577000929682799\n",
      "TIMESTEP 182 / STATE explore / EPSILON 0.09991908099999988 / ACTION 1 / REWARD 0.1 / Q_MAX  2.04506 / Loss  0.0378759279847\n",
      "fps: 0.7633151902908395\n",
      "TIMESTEP 183 / STATE explore / EPSILON 0.09991808199999988 / ACTION 1 / REWARD 0.1 / Q_MAX  1.98508 / Loss  0.137157097459\n",
      "fps: 0.3095798116630501\n",
      "TIMESTEP 184 / STATE explore / EPSILON 0.09991708299999988 / ACTION 0 / REWARD 0.1 / Q_MAX  3.12143 / Loss  0.0314493998885\n",
      "fps: 0.4219167554398068\n",
      "TIMESTEP 185 / STATE explore / EPSILON 0.09991608399999988 / ACTION 1 / REWARD 0.1 / Q_MAX  3.09179 / Loss  0.120909519494\n",
      "fps: 2.7931376636038054\n",
      "TIMESTEP 186 / STATE explore / EPSILON 0.09991508499999988 / ACTION 1 / REWARD 0.1 / Q_MAX  1.10961 / Loss  0.0580922439694\n",
      "fps: 3.7733695349033876\n",
      "TIMESTEP 187 / STATE explore / EPSILON 0.09991408599999987 / ACTION 0 / REWARD 0.1 / Q_MAX  0.226514 / Loss  0.0779778957367\n",
      "fps: 0.2995693484917484\n",
      "TIMESTEP 188 / STATE explore / EPSILON 0.09991308699999987 / ACTION 0 / REWARD -1 / Q_MAX  3.59179 / Loss  0.0279275029898\n",
      "fps: 2.5574073159473945\n",
      "TIMESTEP 189 / STATE explore / EPSILON 0.09991208799999987 / ACTION 0 / REWARD 0.1 / Q_MAX  3.29608 / Loss  0.0380815640092\n",
      "fps: 2.89000848887076\n",
      "TIMESTEP 190 / STATE explore / EPSILON 0.09991108899999987 / ACTION 0 / REWARD 0.1 / Q_MAX  3.10959 / Loss  0.162085607648\n",
      "fps: 5.916820665897376\n",
      "TIMESTEP 191 / STATE explore / EPSILON 0.09991008999999987 / ACTION 1 / REWARD 0.1 / Q_MAX  3.28608 / Loss  0.0440985783935\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 192 / STATE explore / EPSILON 0.09990909099999987 / ACTION 0 / REWARD 0.1 / Q_MAX  3.09315 / Loss  0.0363226085901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 3.520926757607555\n",
      "TIMESTEP 193 / STATE explore / EPSILON 0.09990809199999987 / ACTION 0 / REWARD 0.1 / Q_MAX  3.7065 / Loss  0.085218295455\n",
      "fps: 5.952043684890937\n",
      "TIMESTEP 194 / STATE explore / EPSILON 0.09990709299999986 / ACTION 0 / REWARD 0.1 / Q_MAX  3.45737 / Loss  0.930145084858\n",
      "fps: 6.369056585436964\n",
      "TIMESTEP 195 / STATE explore / EPSILON 0.09990609399999986 / ACTION 0 / REWARD 0.1 / Q_MAX  2.49183 / Loss  0.149331599474\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 196 / STATE explore / EPSILON 0.09990509499999986 / ACTION 0 / REWARD 0.1 / Q_MAX  3.44105 / Loss  0.841553330421\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 197 / STATE explore / EPSILON 0.09990409599999986 / ACTION 0 / REWARD 0.1 / Q_MAX  3.27801 / Loss  0.103698290884\n",
      "fps: 5.78001697774152\n",
      "TIMESTEP 198 / STATE explore / EPSILON 0.09990309699999986 / ACTION 0 / REWARD 0.1 / Q_MAX  2.96313 / Loss  0.0543018132448\n",
      "fps: 5.88202032894294\n",
      "TIMESTEP 199 / STATE explore / EPSILON 0.09990209799999986 / ACTION 0 / REWARD 0.1 / Q_MAX  2.39609 / Loss  0.148477807641\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 200 / STATE explore / EPSILON 0.09990109899999985 / ACTION 0 / REWARD 0.1 / Q_MAX  2.9251 / Loss  0.0884766578674\n",
      "----------Random Action----------\n",
      "fps: 5.290694652925817\n",
      "TIMESTEP 201 / STATE explore / EPSILON 0.09990009999999985 / ACTION 1 / REWARD 0.1 / Q_MAX  3.11745 / Loss  0.0427607148886\n",
      "fps: 2.570547969971998\n",
      "TIMESTEP 202 / STATE explore / EPSILON 0.09989910099999985 / ACTION 0 / REWARD 0.1 / Q_MAX  0.555984 / Loss  0.194521099329\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 203 / STATE explore / EPSILON 0.09989810199999985 / ACTION 0 / REWARD 0.1 / Q_MAX  3.08913 / Loss  0.550964713097\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 204 / STATE explore / EPSILON 0.09989710299999985 / ACTION 0 / REWARD 0.1 / Q_MAX  3.63866 / Loss  0.610213458538\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 205 / STATE explore / EPSILON 0.09989610399999985 / ACTION 0 / REWARD 0.1 / Q_MAX  3.41744 / Loss  0.0713173225522\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 206 / STATE explore / EPSILON 0.09989510499999985 / ACTION 0 / REWARD 0.1 / Q_MAX  1.54253 / Loss  0.051886420697\n",
      "fps: 5.78001697774152\n",
      "TIMESTEP 207 / STATE explore / EPSILON 0.09989410599999984 / ACTION 0 / REWARD 0.1 / Q_MAX  0.00910452 / Loss  0.0293262321502\n",
      "fps: 5.88202032894294\n",
      "TIMESTEP 208 / STATE explore / EPSILON 0.09989310699999984 / ACTION 0 / REWARD 0.1 / Q_MAX  3.05531 / Loss  0.497096985579\n",
      "fps: 4.925817445572136\n",
      "TIMESTEP 209 / STATE explore / EPSILON 0.09989210799999984 / ACTION 1 / REWARD 0.1 / Q_MAX  1.79031 / Loss  0.166556283832\n",
      "fps: 0.2713549223637635\n",
      "TIMESTEP 210 / STATE explore / EPSILON 0.09989110899999984 / ACTION 1 / REWARD 0.1 / Q_MAX  3.17492 / Loss  0.0441165193915\n",
      "----------Random Action----------\n",
      "fps: 1.234496768584246\n",
      "TIMESTEP 211 / STATE explore / EPSILON 0.09989010999999984 / ACTION 1 / REWARD 0.1 / Q_MAX  0.865416 / Loss  0.465946733952\n",
      "fps: 0.7304184886622678\n",
      "TIMESTEP 212 / STATE explore / EPSILON 0.09988911099999984 / ACTION 1 / REWARD 0.1 / Q_MAX  2.6147 / Loss  0.0211142282933\n",
      "----------Random Action----------\n",
      "fps: 0.49650112817382863\n",
      "TIMESTEP 213 / STATE explore / EPSILON 0.09988811199999983 / ACTION 1 / REWARD 0.1 / Q_MAX  2.43993 / Loss  0.075453132391\n",
      "fps: 1.4264520681885813\n",
      "TIMESTEP 214 / STATE explore / EPSILON 0.09988711299999983 / ACTION 0 / REWARD 0.1 / Q_MAX  1.92358 / Loss  0.115672416985\n",
      "fps: 6.4098980970370505\n",
      "TIMESTEP 215 / STATE explore / EPSILON 0.09988611399999983 / ACTION 0 / REWARD 0.1 / Q_MAX  1.71767 / Loss  0.527350664139\n",
      "fps: 0.5941430299211635\n",
      "TIMESTEP 216 / STATE explore / EPSILON 0.09988511499999983 / ACTION 0 / REWARD 0.1 / Q_MAX  3.14733 / Loss  0.457536458969\n",
      "fps: 0.8802313199448815\n",
      "TIMESTEP 217 / STATE explore / EPSILON 0.09988411599999983 / ACTION 0 / REWARD 0.1 / Q_MAX  3.14659 / Loss  0.0809033215046\n",
      "fps: 3.9213432198120994\n",
      "TIMESTEP 218 / STATE explore / EPSILON 0.09988311699999983 / ACTION 0 / REWARD 0.1 / Q_MAX  0.581551 / Loss  0.080583229661\n",
      "fps: 0.17994291581036592\n",
      "TIMESTEP 219 / STATE explore / EPSILON 0.09988211799999983 / ACTION 0 / REWARD 0.1 / Q_MAX  3.02063 / Loss  0.210663050413\n",
      "fps: 0.5851040842020095\n",
      "TIMESTEP 220 / STATE explore / EPSILON 0.09988111899999982 / ACTION 1 / REWARD 0.1 / Q_MAX  2.52769 / Loss  0.0727588236332\n",
      "fps: 2.666512392280771\n",
      "TIMESTEP 221 / STATE explore / EPSILON 0.09988011999999982 / ACTION 0 / REWARD 0.1 / Q_MAX  3.1348 / Loss  0.405111610889\n",
      "fps: 5.34729257157573\n",
      "TIMESTEP 222 / STATE explore / EPSILON 0.09987912099999982 / ACTION 0 / REWARD 0.1 / Q_MAX  1.55227 / Loss  0.0864210575819\n",
      "fps: 5.3472857543537575\n",
      "TIMESTEP 223 / STATE explore / EPSILON 0.09987812199999982 / ACTION 0 / REWARD 0.1 / Q_MAX  2.922 / Loss  0.317961156368\n",
      "fps: 2.793135803554364\n",
      "TIMESTEP 224 / STATE explore / EPSILON 0.09987712299999982 / ACTION 0 / REWARD 0.1 / Q_MAX  2.93421 / Loss  0.194425418973\n",
      "fps: 2.3695334210498067\n",
      "TIMESTEP 225 / STATE explore / EPSILON 0.09987612399999982 / ACTION 1 / REWARD 0.1 / Q_MAX  2.80662 / Loss  0.194904714823\n",
      "----------Random Action----------\n",
      "fps: 6.4098785053870255\n",
      "TIMESTEP 226 / STATE explore / EPSILON 0.09987512499999981 / ACTION 0 / REWARD 0.1 / Q_MAX  2.81186 / Loss  0.0480786338449\n",
      "fps: 6.4098980970370505\n",
      "TIMESTEP 227 / STATE explore / EPSILON 0.09987412599999981 / ACTION 0 / REWARD 0.1 / Q_MAX  2.8799 / Loss  0.0319738835096\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 228 / STATE explore / EPSILON 0.09987312699999981 / ACTION 0 / REWARD 0.1 / Q_MAX  1.63416 / Loss  0.0933602675796\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 229 / STATE explore / EPSILON 0.09987212799999981 / ACTION 0 / REWARD 0.1 / Q_MAX  0.479994 / Loss  0.374550580978\n",
      "fps: 5.376037734639861\n",
      "TIMESTEP 230 / STATE explore / EPSILON 0.09987112899999981 / ACTION 1 / REWARD 0.1 / Q_MAX  2.29744 / Loss  0.369713634253\n",
      "fps: 3.999771131260037\n",
      "TIMESTEP 231 / STATE explore / EPSILON 0.09987012999999981 / ACTION 1 / REWARD 0.1 / Q_MAX  0.985429 / Loss  0.0633105114102\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 232 / STATE explore / EPSILON 0.0998691309999998 / ACTION 0 / REWARD 0.1 / Q_MAX  0.394219 / Loss  0.0126574672759\n",
      "----------Random Action----------\n",
      "fps: 4.255079297607732\n",
      "TIMESTEP 233 / STATE explore / EPSILON 0.0998681319999998 / ACTION 1 / REWARD 0.1 / Q_MAX  1.18468 / Loss  0.0312153436244\n",
      "fps: 5.88201208010961\n",
      "TIMESTEP 234 / STATE explore / EPSILON 0.0998671329999998 / ACTION 0 / REWARD 0.1 / Q_MAX  0.662003 / Loss  0.0927899479866\n",
      "----------Random Action----------\n",
      "fps: 4.950205299427947\n",
      "TIMESTEP 235 / STATE explore / EPSILON 0.0998661339999998 / ACTION 1 / REWARD 0.1 / Q_MAX  1.8688 / Loss  0.0508098304272\n",
      "fps: 2.906810689135872\n",
      "TIMESTEP 236 / STATE explore / EPSILON 0.0998651349999998 / ACTION 0 / REWARD 0.1 / Q_MAX  3.05679 / Loss  0.0677004307508\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 237 / STATE explore / EPSILON 0.0998641359999998 / ACTION 0 / REWARD 0.1 / Q_MAX  2.78122 / Loss  0.115418203175\n",
      "fps: 2.0659977863802785\n",
      "TIMESTEP 238 / STATE explore / EPSILON 0.0998631369999998 / ACTION 1 / REWARD 0.1 / Q_MAX  2.82779 / Loss  0.0507385060191\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 239 / STATE explore / EPSILON 0.0998621379999998 / ACTION 0 / REWARD 0.1 / Q_MAX  0.522906 / Loss  0.0201894231141\n",
      "fps: 3.759182396757694\n",
      "TIMESTEP 240 / STATE explore / EPSILON 0.0998611389999998 / ACTION 0 / REWARD 0.1 / Q_MAX  1.94483 / Loss  0.0508444048464\n",
      "fps: 5.235301900499028\n",
      "TIMESTEP 241 / STATE explore / EPSILON 0.09986013999999979 / ACTION 0 / REWARD 0.1 / Q_MAX  2.93238 / Loss  0.0979671031237\n",
      "fps: 3.105412755258051\n",
      "TIMESTEP 242 / STATE explore / EPSILON 0.09985914099999979 / ACTION 1 / REWARD 0.1 / Q_MAX  2.42801 / Loss  0.0186662487686\n",
      "fps: 5.3472857543537575\n",
      "TIMESTEP 243 / STATE explore / EPSILON 0.09985814199999979 / ACTION 0 / REWARD 0.1 / Q_MAX  2.87437 / Loss  0.0198533795774\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 244 / STATE explore / EPSILON 0.09985714299999979 / ACTION 0 / REWARD 0.1 / Q_MAX  2.97593 / Loss  0.0666486546397\n",
      "----------Random Action----------\n",
      "fps: 3.759182396757694\n",
      "TIMESTEP 245 / STATE explore / EPSILON 0.09985614399999979 / ACTION 0 / REWARD 0.1 / Q_MAX  3.13577 / Loss  0.0694873929024\n",
      "----------Random Action----------\n",
      "fps: 4.67263199172935\n",
      "TIMESTEP 246 / STATE explore / EPSILON 0.09985514499999978 / ACTION 1 / REWARD 0.1 / Q_MAX  2.8905 / Loss  0.126984059811\n",
      "fps: 6.328751331597101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 247 / STATE explore / EPSILON 0.09985414599999978 / ACTION 0 / REWARD 0.1 / Q_MAX  1.59768 / Loss  0.0706109404564\n",
      "fps: 5.34729257157573\n",
      "TIMESTEP 248 / STATE explore / EPSILON 0.09985314699999978 / ACTION 1 / REWARD 0.1 / Q_MAX  3.03396 / Loss  0.0991578325629\n",
      "----------Random Action----------\n",
      "fps: 3.9838340626368334\n",
      "TIMESTEP 249 / STATE explore / EPSILON 0.09985214799999978 / ACTION 0 / REWARD 0.1 / Q_MAX  1.88831 / Loss  0.631474077702\n",
      "fps: 3.086307325070419\n",
      "TIMESTEP 250 / STATE explore / EPSILON 0.09985114899999978 / ACTION 1 / REWARD -1 / Q_MAX  3.08559 / Loss  0.0506854914129\n",
      "fps: 3.1744320078227353\n",
      "TIMESTEP 251 / STATE explore / EPSILON 0.09985014999999978 / ACTION 0 / REWARD 0.1 / Q_MAX  2.77287 / Loss  0.0428456813097\n",
      "fps: 4.291603228394152\n",
      "TIMESTEP 252 / STATE explore / EPSILON 0.09984915099999978 / ACTION 0 / REWARD 0.1 / Q_MAX  3.07987 / Loss  0.0397121421993\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 253 / STATE explore / EPSILON 0.09984815199999977 / ACTION 0 / REWARD 0.1 / Q_MAX  2.83134 / Loss  0.0816354230046\n",
      "fps: 5.29070132661595\n",
      "TIMESTEP 254 / STATE explore / EPSILON 0.09984715299999977 / ACTION 0 / REWARD 0.1 / Q_MAX  1.25943 / Loss  0.0409848690033\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 255 / STATE explore / EPSILON 0.09984615399999977 / ACTION 0 / REWARD 0.1 / Q_MAX  3.08752 / Loss  0.0952560901642\n",
      "fps: 4.925823230490445\n",
      "TIMESTEP 256 / STATE explore / EPSILON 0.09984515499999977 / ACTION 0 / REWARD 0.1 / Q_MAX  2.25592 / Loss  0.0759993568063\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 257 / STATE explore / EPSILON 0.09984415599999977 / ACTION 0 / REWARD 0.1 / Q_MAX  3.14589 / Loss  0.027573928237\n",
      "fps: 5.34729257157573\n",
      "TIMESTEP 258 / STATE explore / EPSILON 0.09984315699999977 / ACTION 0 / REWARD 0.1 / Q_MAX  1.24595 / Loss  0.0885663628578\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 259 / STATE explore / EPSILON 0.09984215799999976 / ACTION 0 / REWARD 0.1 / Q_MAX  3.24844 / Loss  0.253691792488\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 260 / STATE explore / EPSILON 0.09984115899999976 / ACTION 0 / REWARD 0.1 / Q_MAX  3.27053 / Loss  0.16364505887\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 261 / STATE explore / EPSILON 0.09984015999999976 / ACTION 0 / REWARD 0.1 / Q_MAX  1.63642 / Loss  0.0159273128957\n",
      "fps: 5.746794893752287\n",
      "TIMESTEP 262 / STATE explore / EPSILON 0.09983916099999976 / ACTION 0 / REWARD 0.1 / Q_MAX  2.2998 / Loss  0.0294631458819\n",
      "fps: 5.88202032894294\n",
      "TIMESTEP 263 / STATE explore / EPSILON 0.09983816199999976 / ACTION 0 / REWARD 0.1 / Q_MAX  1.02457 / Loss  0.0410435795784\n",
      "fps: 7.142438231923397\n",
      "TIMESTEP 264 / STATE explore / EPSILON 0.09983716299999976 / ACTION 0 / REWARD 0.1 / Q_MAX  2.35736 / Loss  0.0343173220754\n",
      "fps: 6.4098980970370505\n",
      "TIMESTEP 265 / STATE explore / EPSILON 0.09983616399999976 / ACTION 0 / REWARD 0.1 / Q_MAX  1.50641 / Loss  0.0433687642217\n",
      "fps: 6.369056585436964\n",
      "TIMESTEP 266 / STATE explore / EPSILON 0.09983516499999975 / ACTION 0 / REWARD 0.1 / Q_MAX  1.78477 / Loss  0.0598911046982\n",
      "fps: 3.378185142378492\n",
      "TIMESTEP 267 / STATE explore / EPSILON 0.09983416599999975 / ACTION 1 / REWARD 0.1 / Q_MAX  3.19726 / Loss  0.0259127505124\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 268 / STATE explore / EPSILON 0.09983316699999975 / ACTION 0 / REWARD 0.1 / Q_MAX  1.57316 / Loss  0.121878542006\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 269 / STATE explore / EPSILON 0.09983216799999975 / ACTION 0 / REWARD 0.1 / Q_MAX  2.95403 / Loss  0.0238107666373\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 270 / STATE explore / EPSILON 0.09983116899999975 / ACTION 0 / REWARD 0.1 / Q_MAX  3.35783 / Loss  0.046777267009\n",
      "fps: 4.925829015422341\n",
      "TIMESTEP 271 / STATE explore / EPSILON 0.09983016999999975 / ACTION 1 / REWARD 0.1 / Q_MAX  1.67334 / Loss  0.106653526425\n",
      "----------Random Action----------\n",
      "fps: 5.31883967916812\n",
      "TIMESTEP 272 / STATE explore / EPSILON 0.09982917099999974 / ACTION 1 / REWARD 0.1 / Q_MAX  3.39074 / Loss  0.572562217712\n",
      "fps: 5.3472857543537575\n",
      "TIMESTEP 273 / STATE explore / EPSILON 0.09982817199999974 / ACTION 1 / REWARD 0.1 / Q_MAX  2.01459 / Loss  0.0595143027604\n",
      "fps: 5.84762696126681\n",
      "TIMESTEP 274 / STATE explore / EPSILON 0.09982717299999974 / ACTION 1 / REWARD 0.1 / Q_MAX  3.19545 / Loss  0.0998468920588\n",
      "fps: 4.255070664154794\n",
      "TIMESTEP 275 / STATE explore / EPSILON 0.09982617399999974 / ACTION 1 / REWARD 0.1 / Q_MAX  3.05866 / Loss  0.144917860627\n",
      "----------Random Action----------\n",
      "fps: 6.451256858001116\n",
      "TIMESTEP 276 / STATE explore / EPSILON 0.09982517499999974 / ACTION 0 / REWARD 0.1 / Q_MAX  2.49278 / Loss  0.0527539178729\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 277 / STATE explore / EPSILON 0.09982417599999974 / ACTION 0 / REWARD 0.1 / Q_MAX  3.37412 / Loss  0.438004285097\n",
      "----------Random Action----------\n",
      "fps: 5.3760239532317255\n",
      "TIMESTEP 278 / STATE explore / EPSILON 0.09982317699999974 / ACTION 1 / REWARD 0.1 / Q_MAX  3.43511 / Loss  0.0368872359395\n",
      "fps: 2.5574010786157864\n",
      "TIMESTEP 279 / STATE explore / EPSILON 0.09982217799999973 / ACTION 1 / REWARD 0.1 / Q_MAX  1.62296 / Loss  0.0373554155231\n",
      "----------Random Action----------\n",
      "fps: 4.950211141770664\n",
      "TIMESTEP 280 / STATE explore / EPSILON 0.09982117899999973 / ACTION 1 / REWARD 0.1 / Q_MAX  3.05213 / Loss  0.116166345775\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 281 / STATE explore / EPSILON 0.09982017999999973 / ACTION 0 / REWARD 0.1 / Q_MAX  1.74751 / Loss  0.0236895661801\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 282 / STATE explore / EPSILON 0.09981918099999973 / ACTION 0 / REWARD 0.1 / Q_MAX  1.65023 / Loss  0.339517533779\n",
      "fps: 2.6383700910781873\n",
      "TIMESTEP 283 / STATE explore / EPSILON 0.09981818199999973 / ACTION 1 / REWARD 0.1 / Q_MAX  3.35471 / Loss  0.38379278779\n",
      "fps: 5.46417214151623\n",
      "TIMESTEP 284 / STATE explore / EPSILON 0.09981718299999973 / ACTION 0 / REWARD 0.1 / Q_MAX  1.9733 / Loss  0.0999766662717\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 285 / STATE explore / EPSILON 0.09981618399999972 / ACTION 1 / REWARD 0.1 / Q_MAX  3.01913 / Loss  0.0349242165685\n",
      "fps: 5.290708000322919\n",
      "TIMESTEP 286 / STATE explore / EPSILON 0.09981518499999972 / ACTION 0 / REWARD 0.1 / Q_MAX  3.40042 / Loss  0.0226161293685\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 287 / STATE explore / EPSILON 0.09981418599999972 / ACTION 0 / REWARD 0.1 / Q_MAX  2.45019 / Loss  0.46280759573\n",
      "fps: 5.847602503384365\n",
      "TIMESTEP 288 / STATE explore / EPSILON 0.09981318699999972 / ACTION 0 / REWARD 0.1 / Q_MAX  3.37431 / Loss  0.0223952513188\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 289 / STATE explore / EPSILON 0.09981218799999972 / ACTION 0 / REWARD 0.1 / Q_MAX  0.609745 / Loss  0.27349370718\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 290 / STATE explore / EPSILON 0.09981118899999972 / ACTION 0 / REWARD 0.1 / Q_MAX  0.876404 / Loss  0.0231388155371\n",
      "fps: 4.974841745314629\n",
      "TIMESTEP 291 / STATE explore / EPSILON 0.09981018999999972 / ACTION 1 / REWARD 0.1 / Q_MAX  3.24355 / Loss  0.405206531286\n",
      "fps: 4.901680170436152\n",
      "TIMESTEP 292 / STATE explore / EPSILON 0.09980919099999971 / ACTION 1 / REWARD 0.1 / Q_MAX  1.76383 / Loss  0.480241537094\n",
      "fps: 5.84762696126681\n",
      "TIMESTEP 293 / STATE explore / EPSILON 0.09980819199999971 / ACTION 1 / REWARD 0.1 / Q_MAX  2.97587 / Loss  0.0481429472566\n",
      "fps: 5.235301900499028\n",
      "TIMESTEP 294 / STATE explore / EPSILON 0.09980719299999971 / ACTION 0 / REWARD -1 / Q_MAX  1.06737 / Loss  0.0353181362152\n",
      "fps: 6.622139140100035\n",
      "TIMESTEP 295 / STATE explore / EPSILON 0.09980619399999971 / ACTION 0 / REWARD 0.1 / Q_MAX  2.95136 / Loss  0.105133853853\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 296 / STATE explore / EPSILON 0.09980519499999971 / ACTION 0 / REWARD 0.1 / Q_MAX  3.26812 / Loss  0.0243497043848\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 297 / STATE explore / EPSILON 0.0998041959999997 / ACTION 0 / REWARD 0.1 / Q_MAX  3.05359 / Loss  0.0664897561073\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 298 / STATE explore / EPSILON 0.0998031969999997 / ACTION 0 / REWARD 0.1 / Q_MAX  3.01039 / Loss  0.235755607486\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 299 / STATE explore / EPSILON 0.0998021979999997 / ACTION 0 / REWARD 0.1 / Q_MAX  2.91365 / Loss  0.115240588784\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 300 / STATE explore / EPSILON 0.0998011989999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.70002 / Loss  0.0670746937394\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 301 / STATE explore / EPSILON 0.0998001999999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.8637 / Loss  0.0974838733673\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 302 / STATE explore / EPSILON 0.0997992009999997 / ACTION 0 / REWARD 0.1 / Q_MAX  3.39667 / Loss  0.0432865284383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 6.409888301197068\n",
      "TIMESTEP 303 / STATE explore / EPSILON 0.0997982019999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.86754 / Loss  0.330304682255\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 304 / STATE explore / EPSILON 0.0997972029999997 / ACTION 0 / REWARD 0.1 / Q_MAX  2.05316 / Loss  0.110023260117\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 305 / STATE explore / EPSILON 0.0997962039999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.86959 / Loss  0.106744147837\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 306 / STATE explore / EPSILON 0.09979520499999969 / ACTION 0 / REWARD 0.1 / Q_MAX  1.20923 / Loss  0.140210419893\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 307 / STATE explore / EPSILON 0.09979420599999969 / ACTION 0 / REWARD 0.1 / Q_MAX  3.01818 / Loss  0.338230550289\n",
      "----------Random Action----------\n",
      "fps: 7.142438231923397\n",
      "TIMESTEP 308 / STATE explore / EPSILON 0.09979320699999969 / ACTION 0 / REWARD 0.1 / Q_MAX  3.00581 / Loss  0.0178816914558\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 309 / STATE explore / EPSILON 0.09979220799999969 / ACTION 0 / REWARD 0.1 / Q_MAX  1.42407 / Loss  0.036909814924\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 310 / STATE explore / EPSILON 0.09979120899999969 / ACTION 0 / REWARD 0.1 / Q_MAX  1.85725 / Loss  0.0539491809905\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 311 / STATE explore / EPSILON 0.09979020999999968 / ACTION 0 / REWARD 0.1 / Q_MAX  2.93562 / Loss  0.0471413955092\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 312 / STATE explore / EPSILON 0.09978921099999968 / ACTION 0 / REWARD 0.1 / Q_MAX  3.01851 / Loss  0.0226147063076\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 313 / STATE explore / EPSILON 0.09978821199999968 / ACTION 0 / REWARD 0.1 / Q_MAX  2.11067 / Loss  0.0406834818423\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 314 / STATE explore / EPSILON 0.09978721299999968 / ACTION 0 / REWARD 0.1 / Q_MAX  2.87618 / Loss  0.103108882904\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 315 / STATE explore / EPSILON 0.09978621399999968 / ACTION 0 / REWARD 0.1 / Q_MAX  2.64731 / Loss  0.040362406522\n",
      "fps: 3.1947060382727597\n",
      "TIMESTEP 316 / STATE explore / EPSILON 0.09978521499999968 / ACTION 0 / REWARD 0.1 / Q_MAX  3.07062 / Loss  0.0335604771972\n",
      "fps: 5.916820665897376\n",
      "TIMESTEP 317 / STATE explore / EPSILON 0.09978421599999968 / ACTION 0 / REWARD 0.1 / Q_MAX  2.16411 / Loss  0.0280196368694\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 318 / STATE explore / EPSILON 0.09978321699999967 / ACTION 0 / REWARD 0.1 / Q_MAX  2.64172 / Loss  0.489471018314\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 319 / STATE explore / EPSILON 0.09978221799999967 / ACTION 0 / REWARD 0.1 / Q_MAX  3.42707 / Loss  0.0579068809748\n",
      "fps: 6.4098980970370505\n",
      "TIMESTEP 320 / STATE explore / EPSILON 0.09978121899999967 / ACTION 0 / REWARD 0.1 / Q_MAX  0.449728 / Loss  0.111308157444\n",
      "fps: 5.31883293430183\n",
      "TIMESTEP 321 / STATE explore / EPSILON 0.09978021999999967 / ACTION 1 / REWARD 0.1 / Q_MAX  3.08178 / Loss  0.202409088612\n",
      "fps: 5.882028577799406\n",
      "TIMESTEP 322 / STATE explore / EPSILON 0.09977922099999967 / ACTION 1 / REWARD 0.1 / Q_MAX  3.32532 / Loss  0.0689413547516\n",
      "fps: 5.847610655989114\n",
      "TIMESTEP 323 / STATE explore / EPSILON 0.09977822199999967 / ACTION 1 / REWARD 0.1 / Q_MAX  3.20996 / Loss  0.0265473127365\n",
      "fps: 7.091789236614246\n",
      "TIMESTEP 324 / STATE explore / EPSILON 0.09977722299999967 / ACTION 0 / REWARD 0.1 / Q_MAX  3.23269 / Loss  0.0196010116488\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 325 / STATE explore / EPSILON 0.09977622399999966 / ACTION 0 / REWARD 0.1 / Q_MAX  3.27215 / Loss  0.0196832958609\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 326 / STATE explore / EPSILON 0.09977522499999966 / ACTION 1 / REWARD 0.1 / Q_MAX  3.33492 / Loss  0.0262447614223\n",
      "fps: 7.091789236614246\n",
      "TIMESTEP 327 / STATE explore / EPSILON 0.09977422599999966 / ACTION 0 / REWARD 0.1 / Q_MAX  2.76734 / Loss  0.0891201943159\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 328 / STATE explore / EPSILON 0.09977322699999966 / ACTION 1 / REWARD 0.1 / Q_MAX  3.26058 / Loss  0.0926251038909\n",
      "fps: 4.8306448454973685\n",
      "TIMESTEP 329 / STATE explore / EPSILON 0.09977222799999966 / ACTION 1 / REWARD -1 / Q_MAX  3.30389 / Loss  0.0265416316688\n",
      "fps: 5.52454186111144\n",
      "TIMESTEP 330 / STATE explore / EPSILON 0.09977122899999966 / ACTION 1 / REWARD 0.1 / Q_MAX  3.16838 / Loss  0.106872171164\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 331 / STATE explore / EPSILON 0.09977022999999965 / ACTION 0 / REWARD 0.1 / Q_MAX  1.72904 / Loss  0.122072353959\n",
      "----------Random Action----------\n",
      "fps: 5.376037734639861\n",
      "TIMESTEP 332 / STATE explore / EPSILON 0.09976923099999965 / ACTION 1 / REWARD 0.1 / Q_MAX  1.12636 / Loss  0.157356768847\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 333 / STATE explore / EPSILON 0.09976823199999965 / ACTION 0 / REWARD 0.1 / Q_MAX  3.38123 / Loss  0.0481266304851\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 334 / STATE explore / EPSILON 0.09976723299999965 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.880195 / Loss  0.219020664692\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 335 / STATE explore / EPSILON 0.09976623399999965 / ACTION 0 / REWARD 0.1 / Q_MAX  3.49944 / Loss  0.0460520274937\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 336 / STATE explore / EPSILON 0.09976523499999965 / ACTION 0 / REWARD 0.1 / Q_MAX  3.11309 / Loss  0.107707247138\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 337 / STATE explore / EPSILON 0.09976423599999965 / ACTION 0 / REWARD 0.1 / Q_MAX  3.18526 / Loss  0.406239122152\n",
      "fps: 5.847610655989114\n",
      "TIMESTEP 338 / STATE explore / EPSILON 0.09976323699999964 / ACTION 0 / REWARD 0.1 / Q_MAX  2.88456 / Loss  0.0587141029537\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 339 / STATE explore / EPSILON 0.09976223799999964 / ACTION 0 / REWARD 0.1 / Q_MAX  2.89542 / Loss  0.0500388592482\n",
      "fps: 6.369056585436964\n",
      "TIMESTEP 340 / STATE explore / EPSILON 0.09976123899999964 / ACTION 0 / REWARD 0.1 / Q_MAX  1.94851 / Loss  0.0355121009052\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 341 / STATE explore / EPSILON 0.09976023999999964 / ACTION 0 / REWARD 0.1 / Q_MAX  1.18053 / Loss  0.024686910212\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 342 / STATE explore / EPSILON 0.09975924099999964 / ACTION 0 / REWARD 0.1 / Q_MAX  3.25402 / Loss  0.13319619\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 343 / STATE explore / EPSILON 0.09975824199999964 / ACTION 0 / REWARD 0.1 / Q_MAX  0.18015 / Loss  0.443026989698\n",
      "fps: 5.88201208010961\n",
      "TIMESTEP 344 / STATE explore / EPSILON 0.09975724299999963 / ACTION 0 / REWARD 0.1 / Q_MAX  0.784118 / Loss  0.0337258502841\n",
      "fps: 6.4098980970370505\n",
      "TIMESTEP 345 / STATE explore / EPSILON 0.09975624399999963 / ACTION 0 / REWARD 0.1 / Q_MAX  3.10475 / Loss  0.100682280958\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 346 / STATE explore / EPSILON 0.09975524499999963 / ACTION 0 / REWARD 0.1 / Q_MAX  3.3244 / Loss  0.295538038015\n",
      "fps: 4.761639002194464\n",
      "TIMESTEP 347 / STATE explore / EPSILON 0.09975424599999963 / ACTION 1 / REWARD 0.1 / Q_MAX  3.50106 / Loss  0.111496374011\n",
      "fps: 1.2224235807478452\n",
      "TIMESTEP 348 / STATE explore / EPSILON 0.09975324699999963 / ACTION 0 / REWARD 0.1 / Q_MAX  3.0181 / Loss  0.0650571882725\n",
      "fps: 5.290708000322919\n",
      "TIMESTEP 349 / STATE explore / EPSILON 0.09975224799999963 / ACTION 0 / REWARD 0.1 / Q_MAX  2.78163 / Loss  0.12032417953\n",
      "fps: 5.4050866503778385\n",
      "TIMESTEP 350 / STATE explore / EPSILON 0.09975124899999963 / ACTION 1 / REWARD 0.1 / Q_MAX  1.85715 / Loss  0.0278369821608\n",
      "----------Random Action----------\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 351 / STATE explore / EPSILON 0.09975024999999962 / ACTION 0 / REWARD 0.1 / Q_MAX  2.46938 / Loss  0.0493489429355\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 352 / STATE explore / EPSILON 0.09974925099999962 / ACTION 1 / REWARD 0.1 / Q_MAX  2.2023 / Loss  0.0557584650815\n",
      "fps: 4.8306448454973685\n",
      "TIMESTEP 353 / STATE explore / EPSILON 0.09974825199999962 / ACTION 1 / REWARD -1 / Q_MAX  1.72976 / Loss  0.0800951272249\n",
      "fps: 5.075852721386863\n",
      "TIMESTEP 354 / STATE explore / EPSILON 0.09974725299999962 / ACTION 1 / REWARD 0.1 / Q_MAX  2.86288 / Loss  0.1395983845\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 355 / STATE explore / EPSILON 0.09974625399999962 / ACTION 0 / REWARD 0.1 / Q_MAX  1.98201 / Loss  0.0298550557345\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 356 / STATE explore / EPSILON 0.09974525499999962 / ACTION 0 / REWARD 0.1 / Q_MAX  2.95697 / Loss  0.0547238849103\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 357 / STATE explore / EPSILON 0.09974425599999961 / ACTION 1 / REWARD 0.1 / Q_MAX  3.0056 / Loss  0.0431983694434\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 358 / STATE explore / EPSILON 0.09974325699999961 / ACTION 0 / REWARD 0.1 / Q_MAX  1.84173 / Loss  0.0803929120302\n",
      "fps: 6.409888301197068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 359 / STATE explore / EPSILON 0.09974225799999961 / ACTION 0 / REWARD 0.1 / Q_MAX  3.08172 / Loss  0.120293751359\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 360 / STATE explore / EPSILON 0.09974125899999961 / ACTION 0 / REWARD 0.1 / Q_MAX  3.51618 / Loss  0.0484970100224\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 361 / STATE explore / EPSILON 0.09974025999999961 / ACTION 1 / REWARD 0.1 / Q_MAX  2.95249 / Loss  0.137399092317\n",
      "fps: 6.369046914030172\n",
      "TIMESTEP 362 / STATE explore / EPSILON 0.09973926099999961 / ACTION 0 / REWARD 0.1 / Q_MAX  3.29603 / Loss  0.0824349820614\n",
      "fps: 6.451256858001116\n",
      "TIMESTEP 363 / STATE explore / EPSILON 0.0997382619999996 / ACTION 0 / REWARD 0.1 / Q_MAX  2.57117 / Loss  0.0274202488363\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 364 / STATE explore / EPSILON 0.0997372629999996 / ACTION 1 / REWARD 0.1 / Q_MAX  3.23346 / Loss  0.0488679111004\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 365 / STATE explore / EPSILON 0.0997362639999996 / ACTION 1 / REWARD 0.1 / Q_MAX  3.10323 / Loss  0.0179761648178\n",
      "fps: 5.318846424051515\n",
      "TIMESTEP 366 / STATE explore / EPSILON 0.0997352649999996 / ACTION 1 / REWARD 0.1 / Q_MAX  1.57271 / Loss  0.120835661888\n",
      "----------Random Action----------\n",
      "fps: 5.88202032894294\n",
      "TIMESTEP 367 / STATE explore / EPSILON 0.0997342659999996 / ACTION 1 / REWARD 0.1 / Q_MAX  3.05735 / Loss  0.232707202435\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 368 / STATE explore / EPSILON 0.0997332669999996 / ACTION 0 / REWARD 0.1 / Q_MAX  2.91124 / Loss  0.0183467473835\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 369 / STATE explore / EPSILON 0.0997322679999996 / ACTION 0 / REWARD 0.1 / Q_MAX  3.48138 / Loss  0.0683735311031\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 370 / STATE explore / EPSILON 0.0997312689999996 / ACTION 0 / REWARD 0.1 / Q_MAX  3.34074 / Loss  0.314277172089\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 371 / STATE explore / EPSILON 0.0997302699999996 / ACTION 0 / REWARD 0.1 / Q_MAX  3.38176 / Loss  0.041289165616\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 372 / STATE explore / EPSILON 0.09972927099999959 / ACTION 0 / REWARD 0.1 / Q_MAX  3.18274 / Loss  0.22619985044\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 373 / STATE explore / EPSILON 0.09972827199999959 / ACTION 0 / REWARD 0.1 / Q_MAX  3.25752 / Loss  0.135627180338\n",
      "fps: 5.3472857543537575\n",
      "TIMESTEP 374 / STATE explore / EPSILON 0.09972727299999959 / ACTION 1 / REWARD 0.1 / Q_MAX  1.58746 / Loss  0.153252869844\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 375 / STATE explore / EPSILON 0.09972627399999959 / ACTION 0 / REWARD 0.1 / Q_MAX  2.45477 / Loss  0.0738712400198\n",
      "----------Random Action----------\n",
      "fps: 5.34729257157573\n",
      "TIMESTEP 376 / STATE explore / EPSILON 0.09972527499999959 / ACTION 1 / REWARD 0.1 / Q_MAX  1.5123 / Loss  0.146529138088\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 377 / STATE explore / EPSILON 0.09972427599999958 / ACTION 0 / REWARD 0.1 / Q_MAX  1.89009 / Loss  0.0666223391891\n",
      "fps: 6.369046914030172\n",
      "TIMESTEP 378 / STATE explore / EPSILON 0.09972327699999958 / ACTION 0 / REWARD 0.1 / Q_MAX  3.33649 / Loss  0.0411594435573\n",
      "fps: 5.376037734639861\n",
      "TIMESTEP 379 / STATE explore / EPSILON 0.09972227799999958 / ACTION 1 / REWARD 0.1 / Q_MAX  3.13168 / Loss  0.0105407545343\n",
      "----------Random Action----------\n",
      "fps: 0.5707494292238996\n",
      "TIMESTEP 380 / STATE explore / EPSILON 0.09972127899999958 / ACTION 0 / REWARD -1 / Q_MAX  3.3474 / Loss  0.0476698838174\n",
      "fps: 5.07587729223873\n",
      "TIMESTEP 381 / STATE explore / EPSILON 0.09972027999999958 / ACTION 0 / REWARD 0.1 / Q_MAX  2.99928 / Loss  0.0618552006781\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 382 / STATE explore / EPSILON 0.09971928099999958 / ACTION 0 / REWARD 0.1 / Q_MAX  3.26624 / Loss  0.337899655104\n",
      "fps: 4.586896468761278\n",
      "TIMESTEP 383 / STATE explore / EPSILON 0.09971828199999958 / ACTION 0 / REWARD 0.1 / Q_MAX  2.65933 / Loss  0.159168750048\n",
      "----------Random Action----------\n",
      "fps: 5.78001697774152\n",
      "TIMESTEP 384 / STATE explore / EPSILON 0.09971728299999957 / ACTION 1 / REWARD 0.1 / Q_MAX  3.0636 / Loss  0.159135609865\n",
      "fps: 5.916820665897376\n",
      "TIMESTEP 385 / STATE explore / EPSILON 0.09971628399999957 / ACTION 0 / REWARD 0.1 / Q_MAX  2.88502 / Loss  0.307005703449\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 386 / STATE explore / EPSILON 0.09971528499999957 / ACTION 0 / REWARD 0.1 / Q_MAX  2.49782 / Loss  0.0212148223072\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 387 / STATE explore / EPSILON 0.09971428599999957 / ACTION 1 / REWARD 0.1 / Q_MAX  0.609096 / Loss  0.0645204484463\n",
      "fps: 5.916820665897376\n",
      "TIMESTEP 388 / STATE explore / EPSILON 0.09971328699999957 / ACTION 0 / REWARD 0.1 / Q_MAX  2.82913 / Loss  0.0557718686759\n",
      "fps: 6.4098980970370505\n",
      "TIMESTEP 389 / STATE explore / EPSILON 0.09971228799999957 / ACTION 0 / REWARD 0.1 / Q_MAX  1.77245 / Loss  0.14443705976\n",
      "fps: 6.369056585436964\n",
      "TIMESTEP 390 / STATE explore / EPSILON 0.09971128899999956 / ACTION 0 / REWARD 0.1 / Q_MAX  2.61002 / Loss  0.081467539072\n",
      "fps: 5.84762696126681\n",
      "TIMESTEP 391 / STATE explore / EPSILON 0.09971028999999956 / ACTION 0 / REWARD 0.1 / Q_MAX  1.08403 / Loss  0.0540010035038\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 392 / STATE explore / EPSILON 0.09970929099999956 / ACTION 0 / REWARD 0.1 / Q_MAX  2.7809 / Loss  0.0259445570409\n",
      "fps: 5.813617349215898\n",
      "TIMESTEP 393 / STATE explore / EPSILON 0.09970829199999956 / ACTION 0 / REWARD 0.1 / Q_MAX  2.25198 / Loss  0.030007828027\n",
      "fps: 5.88202032894294\n",
      "TIMESTEP 394 / STATE explore / EPSILON 0.09970729299999956 / ACTION 0 / REWARD 0.1 / Q_MAX  1.81101 / Loss  0.214358523488\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 395 / STATE explore / EPSILON 0.09970629399999956 / ACTION 0 / REWARD 0.1 / Q_MAX  1.62693 / Loss  0.0593547970057\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 396 / STATE explore / EPSILON 0.09970529499999956 / ACTION 0 / REWARD 0.1 / Q_MAX  1.79211 / Loss  0.322001576424\n",
      "fps: 5.3472857543537575\n",
      "TIMESTEP 397 / STATE explore / EPSILON 0.09970429599999955 / ACTION 1 / REWARD 0.1 / Q_MAX  1.80124 / Loss  0.0378463082016\n",
      "fps: 5.847618808616596\n",
      "TIMESTEP 398 / STATE explore / EPSILON 0.09970329699999955 / ACTION 0 / REWARD 0.1 / Q_MAX  2.15848 / Loss  0.113898456097\n",
      "fps: 6.451246935341473\n",
      "TIMESTEP 399 / STATE explore / EPSILON 0.09970229799999955 / ACTION 0 / REWARD 0.1 / Q_MAX  2.80787 / Loss  0.0648241713643\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 400 / STATE explore / EPSILON 0.09970129899999955 / ACTION 0 / REWARD 0.1 / Q_MAX  1.32542 / Loss  0.089769795537\n",
      "fps: 5.78001697774152\n",
      "TIMESTEP 401 / STATE explore / EPSILON 0.09970029999999955 / ACTION 0 / REWARD 0.1 / Q_MAX  3.43648 / Loss  0.0348479375243\n",
      "fps: 6.451237012712353\n",
      "TIMESTEP 402 / STATE explore / EPSILON 0.09969930099999955 / ACTION 0 / REWARD 0.1 / Q_MAX  3.20463 / Loss  0.101266220212\n",
      "fps: 5.813625407333175\n",
      "TIMESTEP 403 / STATE explore / EPSILON 0.09969830199999954 / ACTION 1 / REWARD 0.1 / Q_MAX  2.66601 / Loss  0.0600783266127\n",
      "fps: 5.88201208010961\n",
      "TIMESTEP 404 / STATE explore / EPSILON 0.09969730299999954 / ACTION 0 / REWARD 0.1 / Q_MAX  3.27452 / Loss  0.0387333743274\n",
      "fps: 5.847610655989114\n",
      "TIMESTEP 405 / STATE explore / EPSILON 0.09969630399999954 / ACTION 1 / REWARD 0.1 / Q_MAX  2.90278 / Loss  0.0567030496895\n",
      "fps: 5.318846424051515\n",
      "TIMESTEP 406 / STATE explore / EPSILON 0.09969530499999954 / ACTION 1 / REWARD 0.1 / Q_MAX  2.91803 / Loss  0.106242895126\n",
      "fps: 5.88202032894294\n",
      "TIMESTEP 407 / STATE explore / EPSILON 0.09969430599999954 / ACTION 0 / REWARD 0.1 / Q_MAX  3.20443 / Loss  0.149841323495\n",
      "fps: 6.249707950888068\n",
      "TIMESTEP 408 / STATE explore / EPSILON 0.09969330699999954 / ACTION 0 / REWARD -1 / Q_MAX  1.49278 / Loss  0.0151432296261\n",
      "fps: 6.53561684178378\n",
      "TIMESTEP 409 / STATE explore / EPSILON 0.09969230799999954 / ACTION 0 / REWARD 0.1 / Q_MAX  2.70004 / Loss  0.0202307999134\n",
      "fps: 6.409888301197068\n",
      "TIMESTEP 410 / STATE explore / EPSILON 0.09969130899999953 / ACTION 0 / REWARD 0.1 / Q_MAX  3.0396 / Loss  0.0553840212524\n",
      "fps: 3.3668122516112406\n",
      "TIMESTEP 411 / STATE explore / EPSILON 0.09969030999999953 / ACTION 0 / REWARD 0.1 / Q_MAX  1.68068 / Loss  0.0370636470616\n",
      "fps: 2.48130225205932\n",
      "TIMESTEP 412 / STATE explore / EPSILON 0.09968931099999953 / ACTION 0 / REWARD 0.1 / Q_MAX  2.82269 / Loss  0.0460259839892\n",
      "fps: 4.201480128058725\n",
      "TIMESTEP 413 / STATE explore / EPSILON 0.09968831199999953 / ACTION 1 / REWARD 0.1 / Q_MAX  3.11978 / Loss  0.203052416444\n",
      "fps: 4.784413569684941\n",
      "TIMESTEP 414 / STATE explore / EPSILON 0.09968731299999953 / ACTION 0 / REWARD 0.1 / Q_MAX  1.76481 / Loss  0.0246287416667\n",
      "fps: 6.756636940048456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 415 / STATE explore / EPSILON 0.09968631399999953 / ACTION 0 / REWARD 0.1 / Q_MAX  2.38589 / Loss  0.133085682988\n",
      "fps: 6.451395778441226\n",
      "TIMESTEP 416 / STATE explore / EPSILON 0.09968531499999952 / ACTION 0 / REWARD 0.1 / Q_MAX  2.58793 / Loss  0.0145416622981\n",
      "fps: 7.142450394730568\n",
      "TIMESTEP 417 / STATE explore / EPSILON 0.09968431599999952 / ACTION 0 / REWARD 0.1 / Q_MAX  3.30909 / Loss  0.0791775509715\n",
      "fps: 7.142450394730568\n",
      "TIMESTEP 418 / STATE explore / EPSILON 0.09968331699999952 / ACTION 0 / REWARD 0.1 / Q_MAX  3.0527 / Loss  0.0929294675589\n",
      "fps: 7.091789236614246\n",
      "TIMESTEP 419 / STATE explore / EPSILON 0.09968231799999952 / ACTION 0 / REWARD 0.1 / Q_MAX  2.1069 / Loss  0.376366615295\n",
      "fps: 6.369066256873127\n",
      "TIMESTEP 420 / STATE explore / EPSILON 0.09968131899999952 / ACTION 0 / REWARD 0.1 / Q_MAX  3.37916 / Loss  0.318995207548\n",
      "fps: 7.142559861859213\n",
      "TIMESTEP 421 / STATE explore / EPSILON 0.09968031999999952 / ACTION 0 / REWARD 0.1 / Q_MAX  1.88705 / Loss  0.0734240561724\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only join an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7e69fb38eeb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplayGame\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-12216cee503d>\u001b[0m in \u001b[0;36mplayGame\u001b[1;34m(observe)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrainNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-d8111a223a7c>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[1;34m(model, game_state, observe)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m#run the selected action and observed next state and reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mx_t1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fps: {0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlast_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# helpful for measuring frame rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mlast_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-35ecfd7f7a27>\u001b[0m in \u001b[0;36mget_state\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mactions_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# storing actions in a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mis_over\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;31m#game over\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d5bfe251e19a>\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"return Runner.instance_.distanceMeter.digits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_array\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# the javascript object is of type array with score in the formate[1,0,0] which is 100.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only join an iterable"
     ]
    }
   ],
   "source": [
    "playGame (observe=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
